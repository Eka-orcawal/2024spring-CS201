### $逻辑结构$

数据的逻辑结构是指数据元素之间的逻辑关系和组织方式，它独立于数据的具体存储方式。数据的逻辑结构可以分为以下几种主要类型：

1. **集合结构** 最简单的逻辑结构，数据元素之间没有特定的顺序和关系，只是简单地归为一组。
2. **线性结构**有且仅有一个开始节点和一个终端节点，并且除了头尾，每个数据元素都有一个直接前驱和直接后继，是1对1的关系（例如：线性表、栈、队列、串（注意：这四种都是逻辑结构））
3. **非线性结构**一个节点可能有多个直接前驱和后继（树、图）

### $存储结构$

数据在计算机存储设备（如内存、磁盘等）中的实际组织和排列方式。

存储密度$= ($结点数据本身所占的存储量$)/($结点结构所占的存储总量$)$

1. **顺序存储结构 **数据元素按线性顺序存储在连续的内存空间中。通过元素的序号（索引）直接访问元素，访问效率高。
2. **链式存储结构 **数据元素存储在不连续的内存空间中，每个元素通过指针或引用链接在一起。链式存储结构的插入和删除操作是通过修改指针进行的。
3. **索引存储结构**在数据元素之外建立索引表，通过索引表来快速定位数据元素。常用于大规模数据的查找操作。
   - **缺点**：需要额外的存储空间存储索引表。插入和删除操作较复杂，需要维护索引表。
   - **例子**：数据库索引 (B树、B+树)、倒排表
4. **散列存储结构 **通过散列函数将数据元素的关键字映射到存储地址，实现快速查找和存储（哈希表）
   - - 需要设计良好的散列函数以减少冲突，处理冲突的方法可能影响性能。
   - **开放地址法**：线性探测法、二次探测法、随机探测法
   - **链地址法**：同义词的记录存储在一个单链表中，在散列表中只存储所有同义词子表的头指针
     - 处理简单，无堆积现象，非同义词决不会发生冲突，因此**平均查找长度较短**
     - 由于拉链法中各链表上的结点空间是动态申请的，故它更**适合于造表前无法确定表长**的情况
     - 在用拉链法构造的散列表中，**删除结点的操作易于实现**。只要简单地删去链表上相应的结点即可。
     - **缺点**：指针需要额外的空间，故当结点规模较小时，开放定址法较为节省空间，而若将节省的指针空间用来扩大散列表的规模，可使装填因子变小，这又减少了开放定址法中的冲突，从而提高平均查找速度

一个逻辑结构可以有多种类型的存储结构，且不同类型的存储结构会直接影响到数据处理的效率。基于顺序表实现的逻辑结构也不一定是线性结构，比如堆。

两种基本类型的索引：**顺序索引**：基于值的顺序排序。**散列索引**：基于将值平均分道若干散列桶中。一个值所属的散列桶是由散列函数（hash function）决定的。

数据的**最小单位**：数据项     ；数据的**基本单位**：数据元素   ；数据结构：带有结构的各数据元素的集合

### $线性表$

线性表（$List$）的定义：零个或多个数据元素的**有限**序列。有唯一的头元素和尾元素，除了头元素外，每个元素都有唯一的前驱元素，除了尾元素外，每个元素都有唯一的后继元素。线性表中的元素属于相同的数据类型，即每个元素所占的空间相同。

​	注意：$Python$中的$List$存储的是引用，所以尽管数据类型多样，$List$中数据类型仍相同

$$
线性表\begin{cases}
顺序存储——顺序表\\
链式存储\begin{cases}
单链表\\
双链表\\
循环链表\end{cases}
\end{cases}
$$

### $链表$

##### 1、单链表

​	在链式结构中，除了要存储数据元素的信息外，还要存储它的后继元素的存储地址。存储数据元素信息的域称为数据域，存储直接后继位置的域称为指针域。指针域中存储的信息称做指针或链。

​	链表中第一个结点的存储位置叫做头指针。有时为了方便对对链表进行操作，会在单链表的第一个结点前附设一个节点，称为头结点，此时头指针指向的结点就是头结点。

​	空链表，头结点的直接后继为空。

##### 2、双链表

在单链表的每个结点中，再设置一个指向其前驱结点的指针域。所以在双向链表中的结点都有两个指针域，一个指向直接后继，另一个指向直接前驱。

##### 3、循环链表

​	将单链表中终端节点的指针端由空指针改为指向头结点，就使整个单链表形成一个环，这种头尾相接的单链表称为单循环链表，简称循环链表。

### 栈

```python
#中序转后序
def midToSuffix(s):
	s = s.split()
	stack,result = [],[]
	priority = {"/": 1, "*": 1, "+": 2, "-": 2}
	for x in s:
		if x == "(":
			stack.append(x)
		elif x == ")":
			while stack[-1] != "(":
				result.append(stack.pop())
			stack.pop()
		elif x in "/*+-":
			while len(stack) >= 1 and stack[-1] != '(' and priority[stack[-1]] <= priority[x]:
				result.append(stack.pop())
			stack.append(x)
		else:
			result.append(x)
	while stack != []:
		result.append(stack.pop())
	return " ".join(result)
print(midToSuffix(input()))
##计算中序表达式
def countMid(s):
	s = s.split()
	stkNum, stkOp = [], []
	priority = {"/": 1, "*": 1, "+": 2, "-": 2}
	for x in s:
		if x == "(":
			stkOp.append(x)
		elif x == ")":
			while stkOp[-1] != "(":
				op = stkOp.pop()
				a, b = stkNum.pop(), stkNum.pop()
				result = eval(str(b) + op + str(a))
				stkNum.append(result)
			stkOp.pop()
		elif x in "/*+-":
			while len(stkOp) >= 1 and stkOp[-1] != '(' and priority[stkOp[-1]] <=
priority[x]:
				op = stkOp.pop()
				a, b = stkNum.pop(), stkNum.pop()
				result = eval(str(b) + op + str(a))
				stkNum.append(result)
			stkOp.append(x)
		else: # 如果是数字，直接⼊栈
			stkNum.append(float(x))
# 清空运算符栈中的剩余运算符
	while len(stkOp) > 0:
		op = stkOp.pop()
		a, b = stkNum.pop(), stkNum.pop()
		result = eval(str(b) + op + str(a))
		stkNum.append(result)
	return stkNum[-1]
#合法出栈序列
def is_valid_pop_sequence(origin,pop_sequence):
	if len(pop_sequence) != len(origin):
		return False
	stack = []
	bank = list(origin)
	for i in pop_sequence:
		while (not stack or stack[-1] != i) and bank:
			stack.append(bank.pop(0))
		if not stack or stack[-1] != i:
			return False
		stack.pop()
	return True
origin = input().strip()
while True:
	try:
		s = input().strip()
		if is_valid_pop_sequence(origin, s):
			print('YES')
		else:
			print('NO')
	except EOFError:
		break
```

### 堆

按完全二叉树的顺序存储方式把元素存储在一个一维数组中，满足根节点值大于（小于）所有子节点值

初始化：对分支节点从下往上依次向下冒泡调整，时间复杂度为$O(n)$

插入：将元素插入最后一位，再进行向上冒泡，时间复杂度为$O(logn)$

删除：删除堆的根节点，将最后一个节点补到根节点位置，再对根节点进行向下冒泡，时间复杂度为$O(logn)$

```python
class BinHeap:
    def __init__(self):
        self.heaplist = [0]
        self.currentSize = 0        
    def percUp(self, i):
        #大的在后
        while i//2>0:
            if self.heaplist[i] < self.heaplist[i//2]:
                tmp=self.heaplist[i//2]
                self.heaplist[i//2]=self.heaplist[i]
                self.heaplist[i]=tmp
            i=i//2  
    def insert(self,k):
        self.heaplist.append(k)
        self.currentSize += 1
        self.percUp(self.currentSize)    
    def percDowm(self,i):
        #小的在后
        while (i*2) <= self.currentSize:
            mc = self.minChild(i)
            if self.heaplist[i]>self.heaplist[mc]:
                tmp=self.heaplist[i]
                self.heaplist[i]=self.heaplist[mc]
                self.heaplist[mc]=tmp
            i=mc            
    def minChild(self,i):
        if i*2+1>self.currentSize:
            return i*2
        else:
            if self.heaplist[i*2]<self.heaplist[i*2+1]:
                return i*2
            else:
                return i*2+1            
    def delMin(self):
        retval=self.heaplist[1]
        self.heaplist[1]=self.heaplist[self.currentSize]
        self.currentSize -= 1
        self.heaplist.pop()
        self.percDowm(1)
        return retval    
    def buildHeap(self,alist):
        i=len(alist)//2
        self.currentSize=len(alist)
        self.heaplist=[0]+alist[:]
        while (i>0):
            #print(f'i={i},{self.heaplist}')
            self.percDowm(i)
            i -= 1
        #print(f'i={i},{self.heaplist}')
n=int(input().strip())
binheap=BinHeap()
for _ in range(n):
    typeint=input().strip()
    if typeint[0]=="1":
        u=int(typeint.split()[1])
        binheap.insert(u)
    else:
        print(binheap.delMin())
```

### $循环队列$

用长度为$n$的数组实现，认为rear指向末端元素下一个空位（新元素插入位置）时：

队空条件为：$rear==front$

队列长度为：$length=(rear-front+n)\%n$

队满：$(rear-front+1)\%n==0$

用链接方式存储的队列，在进行删除运算时头、尾指针可能都要修改

### $排序$

$$
\begin{array}{|c|c|c|c|c|c|c|p{6cm}|}
\hline 
	名称 & 最佳 & 平均 & 最差 & 内存 & 稳定性 & 方法 & 其他备注 \\
\hline
	冒泡排序 & n & n^2 & n^2 & 1 & 是 & 交换 & 代码量极小 \\
\hline
	选择排序 & n^2 & n^2 & n^2 & 1 & 否 & 选择 & 当使用链表代替交换时，稳定,多了O(n)额外空间 \\
\hline
	快速排序 & nlogn & nlogn & n^2 & logn& 否 & 分区 & 通常原地进行，栈空间为O(logn) \\
\hline
	归并排序 & nlogn & nlogn & nlogn & n & 是 & 归并 & 高度可并行化(可优化至O(log n))\\
\hline
	插入排序 & n & n^2 & n^2 & 1 & 是 & 插入 & 最坏有d个逆序对，时间复杂度为O(n + d) \\
\hline
	希尔排序 & nlogn & n^{4/3}& n^{3/2}& 1 & 否 & 插入 & 代码量小 \\
\hline
	堆排序 & nlogn & nlogn & nlogn & 1 & 否 & 选择 & 适合大数据集\\
\hline
\end{array}
$$

```python
1.冒泡排序
def bubble_sort(arr):
	n = len(arr)
	for i in range(n):
		swapped = False
		for j in range(n-i-1):
			if arr[j] > arr[j+1]:
				arr[j], arr[j+1] = arr[j+1], arr[j]
				swapped = True
		if not swapped:
			break
2.选择排序
def selection_sort(arr):
	for p in range(len(arr)-1, 0, -1):
		position = 0
		for location in range(1, p+1):
			if arr[location] > arr[position]:
				position = location
		if p != position:
			arr[p], arr[position] = arr[position], arr[p]
3.快速排序（分治）
def quick_sort(arr, left, right):
	if left < right:
		position = partition(arr, left, right)
		quick_sort(arr, left, position-1)
		quick_sort(arr, position+1, right)
def partition(arr, left, right):
	i = left
	j = right-1
	pivot = arr[right]
	while i <= j:
		while i <= right and arr[i] < pivot:
			i += 1
		while j >= left and arr[j] >= pivot:
			j -= 1
		if i < j:
			arr[i], arr[j] = arr[j], arr[i]
	if arr[i] > pivot:
		arr[i], arr[right] = arr[right], arr[i]
	return i
4.归并排序
def merge_sort(arr):
	if len(arr) > 1:
		mid = len(arr) // 2
		left = arr[:mid]
		right = arr[mid:]
		merge_sort(left)
		merge_sort(right)
		i, j, k = 0, 0, 0
		while i < len(left) and j < len(right):
			if left[i] <= right[j]:
				arr[k] = left[i]
				i += 1
			else:
				arr[k] = right[j]
				j += 1
			k += 1
		while i < len(left):
			arr[k] = left[i]
			i += 1
			k += 1
		while j > len(right):
			arr[k] = right[j]
			j += 1
			k += 1
5.插⼊排序
def insertion_sort(arr):
	for i in range(1, len(arr)):
		key = arr[i]
		j = i-1
		while j >= 0 and key < arr[j]:
			arr[j+1] = arr[j]
			j -= 1
		arr[j+1] = key
6.希尔排序
def shell_sort(arr, n):
		gap = n // 2
		while gap > 0:
			j = gap
			while j < n:
				i = j - gap
				while i >= 0:
					if arr[i+gap] > arr[i]:
						break
					else:
						arr[i+gap], arr[i] = arr[i], arr[i+gap]
					i -= gap
				j += 1
			gap //= 2
7.堆排序
def heapify(arr, n, i):
	largest = i
	l = 2*i + 1
	r = 2*i + 2
	if l < n and arr[l] > arr[largest]:
		largest = l
	if r < n and arr[r] > arr[largest]:
		largest = r
	if largest != i:
		arr[i], arr[largest] = arr[largest], arr[i]
		heapify(arr, n, largest)
def heapsort(arr):
	n = len(arr)
	for i in range(n//2 - 1, -1, -1):
		heapify(arr, n, i)
	for i in range(n-1, 0, -1):
		arr[i], arr[0] = arr[0], arr[i]
		heapify(arr, i, 0)
```

### $二叉树的性质$

一般而言，高度+1=深度

1）第$i$层最个多$2^i$个结点（层数从0开始）
2）高为$h$的二叉树结点总数最多$2^{h+1}-1$
3）结点数为$n$，边的数目为$n-1$
4）$n$个结点的非空二叉树至少有$$\lceil log_2(n+1) \rceil$$层结点，即高度至少为 $\lceil log_2(n+1) \rceil - 1$
5）在任意一棵二叉树中，若叶子结点（度为0）的个数为$n_0$，度为2的结点个数为$n_2$，则，n2=n0-1

6）非空满二叉树叶结点数目等于分支结点数目加1。

​		a）**完全二叉树**中度为1的结点数目为0个或1个

​		c）有$n$个叶结点的完全二叉树有$2n$或$2n-1$个结点（两种都可以构建）

​		d）有$n$个结点的非空完全二叉树的高度为$\lceil log_2(n+1)\rceil - 1$  （层数为$\lceil log_2(n+1)\rceil $）

对一个度为$2$的森林 ，叶子结点总数为$L$，度数为$2$结点总个数为$N$，那么树的个数为$L-N$

### $树的储存$

储存形式：双亲表示法、孩子链表表示法、孩子兄弟表示法 ； 储存结构：顺序储存、链式储存

```python
AVL：
class Node:
    def __init__(self, value):
        self.value = value
        self.left = None
        self.right = None
        self.height = 1
class AVL:
    def __init__(self):
        self.root = None
    def insert(self, value):
        if not self.root: #插入第一个节点
            self.root = Node(value)
        else:
            self.root = self._insert(value, self.root)
    def _insert(self, value, node): #插入后续节点
        if not node:
            return Node(value)
        elif value < node.value:
            node.left = self._insert(value, node.left)
        else:
            node.right = self._insert(value, node.right)
        node.height = 1 + max(self._get_height(node.left), self._get_height(node.right))
        balance = self._get_balance(node)
        if balance > 1: #树偏左
            if value < node.left.value:	# 树形是 LL
                return self._rotate_right(node)
            else:	# 树形是 LR
                node.left = self._rotate_left(node.left)
                return self._rotate_right(node)
        if balance < -1: #树偏右
            if value > node.right.value:	# 树形是 RR
                return self._rotate_left(node)
            else:	# 树形是 RL
                node.right = self._rotate_right(node.right)
                return self._rotate_left(node)
        return node
    def _get_height(self, node):
        if not node:
            return 0
        return node.height
    def _get_balance(self, node): #左height-右height
        if not node:
            return 0
        return self._get_height(node.left) - self._get_height(node.right)
    def _rotate_left(self, z): #左旋
        y = z.right
        T2 = y.left
        y.left = z
        z.right = T2
        z.height = 1 + max(self._get_height(z.left), self._get_height(z.right))
        y.height = 1 + max(self._get_height(y.left), self._get_height(y.right))
        return y
    def _rotate_right(self, y): #右旋
        x = y.left
        T2 = x.right
        x.right = y
        y.left = T2
        y.height = 1 + max(self._get_height(y.left), self._get_height(y.right))
        x.height = 1 + max(self._get_height(x.left), self._get_height(x.right))
        return x
    def preorder(self): #先序遍历（中左右）
        return self._preorder(self.root)
    def _preorder(self, node):
        if not node:
            return []
        return [node.value] + self._preorder(node.left) + self._preorder(node.right)
n = int(input().strip())
sequence = list(map(int, input().strip().split()))
avl = AVL()
for value in sequence:
    avl.insert(value)
print(' '.join(map(str, avl.preorder())))
```

### $BST增删查改$

删：将删除的节点的值替换为左子树最大值或右子树最小值

增：递归搜索，新增的节点一定是叶子节点

### $Huffman算法$

建树：使用$heapq$重复合并权值最小的两个节点（或子树），直到所有节点都合并为一棵树为止

```python
import heapq
class  Node:
    def __init__(self,weight,char=None):
        self.weight=weight
        self.left = None
        self.right = None
        self.char = char
    def __lt__(self,other):
        if self.weight == other.weight:
            return self.char < other.char
        return self.weight < other.weight
def build_huffman_tree(characters):
    heap=[]
    for char,weight in characters.items():
        heapq.heappush(heap,Node(weight,char))       
    while len(heap)>1:
        left = heapq.heappop(heap)
        right = heapq.heappop(heap)
        merged = Node(left.weight + right.weight, min(left.char, right.char))
        merged.left=left
        merged.right=right
        heapq.heappush(heap, merged)
    return heap[0]
def encode_huffman_tree(root): #进行编码
    codes={}
    def traverse(node,code):
        if node.left is None and node.right is None:
            codes[node.char] =code
        else: 
            traverse(node.left, code +"0")
            traverse(node.right,code+"1")
    traverse(root,"")
    return codes
def huffman_encoding(codes, string): #根据字符输出编码
    encoded = ''
    for char in string:
        encoded += codes[char]
    return encoded
def huffman_decoding(root,encoded_string): #根据编码输出字符
    decoded =""
    node = root
    for bit in encoded_string:
        if bit =="0":
            node = node.left
        else:
            node = node.right       
        if node.left is None and node.right is None:
            decoded +=node.char
            node = root
    return decoded
n = int(input())
characters={}
for _ in range(n):
    char,weight =input().strip().split()
    characters[char]=int(weight)
huffman_tree= build_huffman_tree(characters) #建树
codes=encode_huffman_tree(huffman_tree) #编码

while True:
    try:
        inter=input().strip()
        if "0" in inter or "1" in inter:
            print(huffman_decoding(huffman_tree, inter))
        else:
            print(huffman_encoding(codes, inter))
    except EOFError:
        break
```

### $图$

完全图（简单完全图）：任意两个顶点之间都有边，连通图（一般指无向图）：图中任意两顶点连通
连通分量：无向图的极大连通子图（类似全集的概念），极小连通分量：在保持连通的情况下使边数最少的子图（暗指无向图）
强连通图（特指有向图）：任意一对顶点都是强连通的。强连通分量：有向图中的极大强连通子图
生成树：包含图中全部顶点的一个极小连通子图

强连通分支：局部极大强连通子图，一个图中可能不止一个强连通分支

有向图$D=(V,E)$的每个点位于且仅位于$D$的某个强连通分支中。这就是说，所有强连通分支包含所有顶点

对任意一个连通的、无环的无向图，从图中移除任何一条边得到的图均不连通。

事件最早发生时间ve【k】(从头到尾求max)，事件最迟发生时间vl【k】(从尾到前求min)

活动最早发生时间e【i】（上一个事件的ve），活动最迟发生时间l【i】=后一个事件的vl-该活动的时长a

e=l的则为关键活动，可以判断出该AOE网的关键路径（不能成环，所以可能形成多条）

### $拓扑排序$

一般对**有向无环图**使用，当然也可以用来判断环的存在。对于无向图遍历可用dfs、bfs。

每次选择入度为$0$的节点入栈，相应邻接表中元素入度全部$-1$，重复直到全部节点入栈，最后输出栈中元素

AOV（Active On Vertex）网络：在有向图中，用顶点表示活动，用有向边表示前驱是后驱必要活动条件

```python
from collections import deque
def topo_sort(graph):
    in_degree={u:0 for u in range(1,N+1)} #记录入度
    for u in graph:
        for v in graph[u]:
            in_degree[v]+=1
    q=deque([u for u in in_degree if in_degree[u]==0]) #从入度为0的开始
    topo_order=[]
    while q:
        u=q.popleft()
        topo_order.append(u)
        for v in graph[u]:
            in_degree[v]-=1 #将相连点的入度-1
            if in_degree[v]==0:
                q.append(v)
    if len(topo_order)!=len(graph):
        return 'Yes'
    return 'No' 

T=int(input())
for t in range(T):
    N,M=map(int,input().split())
    Map={i:[] for i in range(1,N+1)}
    for m in range(M):
        x,y=map(int,input().split())
        Map[x].append(y)
    print(topo_sort(Map))
```

### $Dijkstra$

带权BFS，求解图中特定两点间最短距离。Dijkstra算法的核心思想是贪心算法。从起始节点开始，逐步扩展到达图中所有其他节点的最短路径。算法维护两组节点集合：已经找到最短路径的节点集合和还没有找到最短路径的节点集合。初始时，起始节点的最短路径值设为0，其他所有节点的最短路径值设为无穷大。算法重复以下步骤直到所有节点的最短路径都被找到：

1. 从还没有找到最短路径的节点集合中选择一个与起始节点最短距离最小的节点。
2. 更新该节点相邻的节点的最短路径值：如果通过该节点到达相邻节点的路径比当前记录的路径更短，就更新这个最短路径值。
3. 将该节点移动到已经找到最短路径的节点集合中。
4. 重复上述步骤，直到所有节点的最短路径都被找到。

对负权边，贪心策略不适用（Prim可以做负权）

```python
import heapq

def dijkstra(adjacency, start):
    distances = {vertex: float('infinity') for vertex in adjacency}
    previous = {vertex: None for vertex in adjacency}
    distances[start] = 0
    pq = [(0, start)]

    while pq:
        current_distance, current_vertex = heapq.heappop(pq)
        if current_distance > distances[current_vertex]:
            continue

        for neighbor, weight in adjacency[current_vertex].items():
            distance = current_distance + weight
            if distance < distances[neighbor]:
                distances[neighbor] = distance
                previous[neighbor] = current_vertex
                heapq.heappush(pq, (distance, neighbor))

    return distances, previous

def shortest_path_to(adjacency, start, end):
    distances, previous = dijkstra(adjacency, start)
    path = []
    current = end
    while previous[current] is not None:
        path.insert(0, current)
        current = previous[current]
    path.insert(0, start)
    return path, distances[end]

P = int(input())
places = {input().strip() for _ in range(P)}

Q = int(input())
graph = {place: {} for place in places}
for _ in range(Q):
    x, y, dist = input().split()
    dist = int(dist)
    graph[x][y] = dist
    graph[y][x] = dist 

R = int(input())
for Rs in range(R):   
    start,end = input().split()
    if start==end:
        print(start)
        continue
    
    path, total_dist = shortest_path_to(graph, start, end)
    output = ""
    for i in range(len(path) - 1):
        output += f"{path[i]}->({graph[path[i]][path[i+1]]})->"
    output += f"{end}"
    print(output)
```

### $最小生成树$

在一给定的**无向图**$\ G = (V, E)$ 中，$(u, v)$ 代表连接顶点$u $与顶点$ v $的边，而$ w(u, v) $代表此的边权重，若存在$ T $为$ E $的子集（即）且为无循环图，使得$ w(T) $最小，则此$ T $为$ G $的最小生成树。最小生成树其实是最小权重生成树的简称。

```python
#Prim（稠密图）
输入:一个无向连通图G(V, E),其中V是顶点集合, E是边集合输出:最小生成树MST
1.初始化一个空的最小生成树tMST和一个空的顶点集合visited
2.选择一个起始顶点s,并将其加入visited中
3.当visited中的顶点数量小于V时，执行以下步骤:
4.遍历visited中的每个顶点v,找到与v相邻的未访问顶点u,并计算边(v, u)的权重
5.选择具有最小权重的边(v, u),将u加入visited, 并将边(v, u)加入MST中
4.返回最小生成树MST
- 邻接矩阵 + 简单数组：$O(V^2)$
- 邻接表 + 二叉堆：$O(Elog V)$
- 邻接表 + 斐波那契堆：$O(Vlog V + E)$
from heapq import heappop, heappush
while True:
    try:
        n = int(input())
    except:
        break
    mat, cur = [], 0
    for i in range(n):
        mat.append(list(map(int, input().split())))
    d, v, q, cnt = [100000 for i in range(n)], set(), [], 0
    d[0] = 0
    heappush(q, (d[0], 0))
    while q:
        x, y = heappop(q)
        if y in v:
            continue
        v.add(y)
        cnt += d[y]
        for i in range(n):
            if d[i] > mat[y][i]:
                d[i] = mat[y][i]
                heappush(q, (d[i], i))
    print(cnt)
#Kruskal（稀疏图）
给出Kruskal算法的基本步骤思想如下:（并查集优化：$O(Elog V)$）
1)将原图中的所有边依据权值按照从小到大的顺序排列。(直接使用库函数sort即可)
2)接下来按照权值从小到大考察每条边(u, v)。这时，若u和v已经处在同-一个连通分量中，那么选择(u, v)后就会形成环，故显然不能选择;如果u和v还不在同一个连通分量中，那么就选择加入这条边。(贪心) 因为当u和v不在同一连通分量中时，加入(u, v)-定是最优的。
```

### $KMP$

给定一个长度为$n$的字符串$s$，其前缀函数被定义为一个长度为$n$的数组$\pi$。其中$\pi[i]$的定义是：

1. 如果子串$s[0…i]$有一对相等的真前缀与真后缀：$s[0…k-1]$和$s[i-(k-1)…i]$，那么$\pi[i]$就是这个相等的真前缀（或者真后缀，因为它们相等）的长度，也就是$\pi[i]=k$；
2. 如果不止有一对相等的，那么$\pi[i]$就是其中最长的那一对的长度；
3. 如果没有相等的，那么$\pi[i]=0$。

简单来说$\pi[i]$就是，子串$s[0…i]$最长的相等的真前缀与真后缀的长度。规定$\pi[0]=0$

用数学语言描述如下：
$$
\pi[i] = \max_{k=0..i} \{ k : s[0 \ldots k-1] = s[i-(k-1) \ldots i] \}
$$
#### $DP和分治$

如果一个问题的最优解可以由其子问题的最优解有效地构造出来，那么称这个问题拥有**最优子结构(Optimal Substructure)**。最优子结构保证了动态规划中原问题的最优解可以由子问题的最优解推导而来。因此，一个问题必须拥有最优子结构，才能使用动态规划去解决。

分治算法通常将原问题分解为几个规模较小但类似于原问题的子问题，求解这些子问题，然后再合并这些子问题的解来建立原问题的解（不一定用递归）

分治和动态规划都是将问题分解为子问题，然后合并子问题的解得到原问题的解。但是不同的是，分治法分解出的子问题是不重叠的，因此分治法解决的问题不拥有重叠子问题，而动态规划解决的问题拥有**重叠子问题**。